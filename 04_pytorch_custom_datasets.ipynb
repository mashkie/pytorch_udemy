{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08263a37-b668-44bd-bdf2-5bf116e90854",
   "metadata": {},
   "source": [
    "# 04. PyTorch Custom Datasets Video Notebook\n",
    "We've used some datasets with PyTorch before.\n",
    "\n",
    "But how do you get your own data into PyTorch?\n",
    "\n",
    "One of the ways to do so is via: custom datasets.\n",
    "\n",
    "## Domain libraries\n",
    "Depending on what you're working on, vision, text, audio, recommendation, you'll want to look into each of the PyTorch domain libraries for existing data loading functions and customizable data loading functions.\n",
    "\n",
    "**Resources:**\n",
    "\n",
    "* Book version of the course materials for 04: https://www.learnpytorch.io/04_pytorch_custom_datasets/\n",
    "* Ground truth version of notebook 04: https://github.com/mrdbourke/pytorch-deep-learning/blob/main/04_pytorch_custom_datasets.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd29089-8012-442b-a638-6ee1296b6759",
   "metadata": {},
   "source": [
    "## 0. Importing PyTorch and setting up device-agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f828c1c-59c1-4e57-88f9-5f9b0fe3ca9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0+cu117'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24dabfec-6f5f-4f85-a72e-af664cf5b964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e58e04c-9627-4554-b4f5-26382e53d185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 10 17:26:58 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.05    Driver Version: 525.85.05    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| 29%   61C    P0    54W / 240W |   2435MiB /  8192MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3325      G   /usr/lib/xorg/Xorg               1416MiB |\n",
      "|    0   N/A  N/A      3475      G   /usr/bin/gnome-shell              156MiB |\n",
      "|    0   N/A  N/A      8191      G   ...380271138922224760,131072       50MiB |\n",
      "|    0   N/A  N/A      8390      G   ...RendererForSitePerProcess       43MiB |\n",
      "|    0   N/A  N/A     11119      G   ...RendererForSitePerProcess       55MiB |\n",
      "|    0   N/A  N/A     17876      G   ...464047926749513724,131072      486MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0990c725-f8d7-4fd9-945d-165b9d93d801",
   "metadata": {},
   "source": [
    "## 1. Get data\n",
    "Our dataset is a subset of the Food101 dataset.\n",
    "\n",
    "Food101 starts 101 different classes of food and 1000 images per class (750 training, 250 testing).\n",
    "\n",
    "Our dataset starts with 3 classes of food and only 10% of the images (~75 training, 25 testing).\n",
    "\n",
    "Why do this?\n",
    "\n",
    "When starting out ML projects, it's important to try things on a small scale and then increase the scale when necessary.\n",
    "\n",
    "The whole point is to speed up how fast you can experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac94aaf-068e-4b05-aa9d-eed846dc1599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
